{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNwN8ktSKFRvgu7lyI7TiYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whitecatdry/EMG/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "id": "NKaIWA09p6CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "2m1DE8Y0p6Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv(\"/content/0.csv\", header=None)\n",
        "print(\"Class 0 Shape\", df0.shape)\n",
        "df1 = pd.read_csv(\"/content/1.csv\", header=None)\n",
        "print(\"Class 1 Shape\", df1.shape)\n",
        "df2 = pd.read_csv(\"/content/2.csv\", header=None)\n",
        "print(\"Class 2 Shape\", df2.shape)\n",
        "df3 = pd.read_csv(\"/content/3.csv\", header=None)\n",
        "print(\"Class 3 Shape\", df3.shape)\n",
        "\n",
        "\n",
        "df = pd.concat([df0,df1,df2,df3])\n",
        "data = df.values\n",
        "\n",
        "sc = MinMaxScaler(feature_range = (0, 1))"
      ],
      "metadata": {
        "id": "WNqsulayp6HI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(data):\n",
        "    \n",
        "    X0, X1, X2, X3=[],[],[],[]\n",
        "    data[:,:-1] = sc.fit_transform(data[:,:-1])\n",
        "    \n",
        "    for i in range(data.shape[0]):\n",
        "        tmp = data[i,:-1].reshape((8,8))\n",
        "        for j in range(8):\n",
        "            \n",
        "            if data[i,-1] == 0:\n",
        "                X0.append(tmp[j,:])\n",
        "            \n",
        "            elif data[i,-1] == 1:\n",
        "                X1.append(tmp[j,:])\n",
        "            \n",
        "            elif data[i,-1] == 2:\n",
        "                X2.append(tmp[j,:])\n",
        "\n",
        "            elif data[i,-1] == 3:\n",
        "                X3.append(tmp[j,:])\n",
        "    \n",
        "    X0, X1, X2, X3 = np.array(X0), np.array(X1), np.array(X2), np.array(X3)    \n",
        "        \n",
        "    fig, axes = plt.subplots(4,8, figsize=(30, 8), sharex=True, sharey=True)\n",
        "    for i in range(8):\n",
        "        axes[0][i].plot(X0[:,i], label='Raw Ch '+str(i))\n",
        "        axes[1][i].plot(X1[:,i], label='Raw Ch '+str(i))\n",
        "        axes[2][i].plot(X2[:,i], label='Raw Ch '+str(i))\n",
        "        axes[3][i].plot(X3[:,i], label='Raw Ch '+str(i))\n",
        "        \n",
        "plot_data(data)"
      ],
      "metadata": {
        "id": "WMahCX64p6Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClickNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_features, n_hidden, n_sequence, n_layers, n_classes):\n",
        "        super(ClickNet, self).__init__()\n",
        "        \n",
        "        self.n_features = n_features\n",
        "        self.n_hidden = n_hidden\n",
        "        self.n_sequence = n_sequence\n",
        "        self.n_layers = n_layers\n",
        "        self.n_classes = n_classes\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, batch_first=True)\n",
        "        \n",
        "        self.linear_1 = nn.Linear(in_features=n_hidden, out_features=128)\n",
        "        self.dropout_1 = nn.Dropout(p=0.2)\n",
        "        \n",
        "        self.linear_2 = nn.Linear(in_features=128, out_features=n_classes)        \n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        self.hidden = (\n",
        "            torch.zeros(self.n_layers, x.shape[0], self.n_hidden).to(device),\n",
        "            torch.zeros(self.n_layers, x.shape[0], self.n_hidden).to(device)\n",
        "        )\n",
        "    \n",
        "        out, (hs, cs) = self.lstm(x.view(len(x), self.n_sequence, -1),self.hidden)\n",
        "        out = out[:,-1,:]\n",
        "        out = self.linear_1(out)\n",
        "        out = self.dropout_1(out)\n",
        "        out = self.linear_2(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "\n",
        "    \n",
        "def train_model(model, train_dataloader, n_epochs):\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    \n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        for i, (X_train, y_train) in enumerate(train_dataloader):\n",
        "            \n",
        "            y_hat = model(X_train)\n",
        "            \n",
        "            loss = loss_fn(y_hat.float(), y_train)\n",
        "\n",
        "            if i == 0 and (epoch+1)%10==0:\n",
        "                print(f'Epoch {epoch+1} train loss: {loss.item()}')\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "bN8waU5kp6Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(a):\n",
        "    a=a.astype(int)\n",
        "    b = np.zeros((a.size, a.max()+1))\n",
        "    b[np.arange(a.size),a] = 1\n",
        "    return b\n",
        "\n",
        "def prepare_data(data):\n",
        "    data[:,:-1] = sc.fit_transform(data[:,:-1])\n",
        "    np.random.shuffle(data)\n",
        "    X, y = data[:,:-1], data[:,-1]\n",
        "    X = X.reshape(-1,8,8)\n",
        "#     y=one_hot(y)\n",
        "    \n",
        "    X_train = torch.from_numpy(X[:7700])\n",
        "    y_train = torch.from_numpy(y[:7700])\n",
        "    X_test = torch.from_numpy(X[7700:])\n",
        "    y_test = torch.from_numpy(y[7700:])\n",
        "    \n",
        "    return X_train.float().to(device), y_train.long().to(device), X_test.float().to(device), y_test.long().to(device)\n",
        "\n",
        "\n",
        "\n",
        "def prepare_data_2():\n",
        "    rock_dataset = pd.read_csv(\"/kaggle/input/emg-4/0.csv\", header=None) # class = 0\n",
        "    scissors_dataset = pd.read_csv(\"/kaggle/input/emg-4/1.csv\", header=None) # class = 1\n",
        "    paper_dataset = pd.read_csv(\"/kaggle/input/emg-4/2.csv\", header=None) # class = 2\n",
        "    ok_dataset = pd.read_csv(\"/kaggle/input/emg-4/3.csv\", header=None) # class = 3\n",
        "\n",
        "    frames = [rock_dataset, scissors_dataset, paper_dataset, ok_dataset]\n",
        "    dataset = pd.concat(frames)\n",
        "\n",
        "    dataset_train = dataset.iloc[np.random.permutation(len(dataset))]\n",
        "    dataset_train.reset_index(drop=True)\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "\n",
        "    for i in range(0, dataset_train.shape[0]):\n",
        "        row = np.array(dataset_train.iloc[i:1+i, 0:64].values)\n",
        "        X_train.append(np.reshape(row, (64, 1)))\n",
        "        y_train.append(np.array(dataset_train.iloc[i:1+i, -1:])[0][0])\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    # Reshape to one flatten vector\n",
        "    X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], 1)\n",
        "    X_train = sc.fit_transform(X_train)\n",
        "\n",
        "    # Reshape again after normalization to (-1, 8, 8)\n",
        "    X_train = X_train.reshape((-1, 8, 8))\n",
        "\n",
        "    # Convert to one hot\n",
        "    y_train = np.eye(np.max(y_train) + 1)[y_train]\n",
        "\n",
        "\n",
        "    # Splitting Train/Test\n",
        "    X_test = torch.from_numpy(X_train[7700:])\n",
        "    y_test = torch.from_numpy(y_train[7700:])\n",
        "      \n",
        "    X_train = torch.from_numpy(X_train[0:7700])\n",
        "    y_train = torch.from_numpy(y_train[0:7700])\n",
        "    \n",
        "    return X_train.float().to(device), y_train.float().to(device), X_test.float().to(device), y_test.float().to(device)"
      ],
      "metadata": {
        "id": "vxmeotWbp6O9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmgDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    \n",
        "n_features=8\n",
        "n_sequence=8\n",
        "n_hidden=64\n",
        "n_layers=1\n",
        "n_classes=4\n",
        "\n",
        "n_epochs = 1000\n",
        "n_batch_size = 256\n",
        "\n",
        "model = ClickNet(n_features, n_hidden, n_sequence, n_layers, n_classes).to(device)\n",
        "X_train, y_train, X_test, y_test = prepare_data(data)\n",
        "# X_train, y_train, X_test, y_test = prepare_data_2()\n",
        "\n",
        "\n",
        "print(\"Train Data Shape \",X_train.shape, y_train.shape)\n",
        "print(\"Test Data Shape \",X_test.shape, y_test.shape)\n",
        "\n",
        "train_dataset = EmgDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(dataset = train_dataset, batch_size=n_batch_size, shuffle=True)\n",
        "model = train_model(model, train_dataloader, n_epochs = n_epochs)"
      ],
      "metadata": {
        "id": "zmIEEEL7p6Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateModel(prediction, y):\n",
        "    prediction = torch.argmax(prediction, dim=1)\n",
        "#     y = torch.argmax(y, dim=1)\n",
        "    good = 0\n",
        "    for i in range(len(y)):\n",
        "        if (prediction[i] == y[i]):\n",
        "            good = good +1\n",
        "    return (good/len(y)) * 100.0\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_hat_train = model(X_train)\n",
        "    print(\"Train Accuracy \", evaluateModel(y_hat_train, y_train))\n",
        "    \n",
        "    y_hat_test = model(X_test)\n",
        "    print(\"Test Accuracy \", evaluateModel(y_hat_test, y_test))"
      ],
      "metadata": {
        "id": "J7Mg39nAp6Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "13gZy4qFp6XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uTtzFmjIp6Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hGGjSMgxp6dS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}